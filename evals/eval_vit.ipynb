{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227c3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26f62ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.basemodule import BaseModel, BaseLightningModule, BaseSpecDataset, BaseDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f0f6073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "config  = load_config('../configs/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d737fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'image_size': 4096,\n",
       "  'patch_size': 100,\n",
       "  'hidden_size': 128,\n",
       "  'num_hidden_layers': 6,\n",
       "  'num_attention_heads': 8,\n",
       "  'num_labels': 2,\n",
       "  'stride_ratio': 1,\n",
       "  'proj_fn': 'SW'},\n",
       " 'train': {'batch_size': 128, 'ep': 1, 'debug': 0, 'workers': 24},\n",
       " 'loss': {'name': 'T1'},\n",
       " 'opt': {'type': 'adam',\n",
       "  'lr': 0.001,\n",
       "  'lr_sch': 'plateau',\n",
       "  'factor': 0.8,\n",
       "  'patience': 2},\n",
       " 'data': {'file_path': '/datascope/subaru/user/swei20/data/bosz50000/test/mag215/train_100k/dataset.h5',\n",
       "  'val_path': '/datascope/subaru/user/swei20/data/bosz50000/mag215/train_1k/dataset.h5',\n",
       "  'test_path': '/datascope/subaru/user/swei20/data/bosz50000/mag215/val_1k/dataset.h5',\n",
       "  'num_samples': 1000,\n",
       "  'num_test_samples': 1000,\n",
       "  'param_idx': 1},\n",
       " 'mask': {'mask_ratio': 0.85},\n",
       " 'noise': {'noise_level': 0},\n",
       " 'project': 'vit-test'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded988a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad4a06",
   "metadata": {},
   "source": [
    "from src.model import MyViT, runs perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1662643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTModel, ViTConfig\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96f7208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_config(config, num_classes=2):\n",
    "    \"\"\"\n",
    "    Create a ViTConfig object based on the provided configuration.\n",
    "    Args:\n",
    "        config (dict): Configuration dictionary containing model parameters.\n",
    "        num_classes (int): Number of output classes for classification tasks.\n",
    "        image_size (int): Size of the input images.\n",
    "    Returns:\n",
    "        ViTConfig: Config object for the Vision Transformer model.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    vit_config = ViTConfig(\n",
    "        image_size=config['model']['image_size'],\n",
    "        patch_size=config['model']['patch_size'],\n",
    "        num_channels=1,\n",
    "        hidden_size=config['model']['hidden_size'],\n",
    "        num_hidden_layers=config['model']['num_hidden_layers'],\n",
    "        num_attention_heads=config['model']['num_attention_heads'],\n",
    "        intermediate_size=4 * config['model']['hidden_size'],\n",
    "        stride_ratio=config['model']['stride_ratio'],\n",
    "        proj_fn=config['model']['proj_fn'],\n",
    "\n",
    "        hidden_act=\"gelu\",\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        is_encoder_decoder=False,\n",
    "        use_mask_token=False,\n",
    "        qkv_bias=True,\n",
    "        num_labels=num_classes,\n",
    "        noise_level=config['noise']['noise_level'],\n",
    "        learning_rate=config['opt']['lr'],\n",
    "    )\n",
    "    return vit_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e26f5d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_config = get_model_config(config, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82b20845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import MyViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53847ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MyViT(vit_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a810dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(2, 4096)\n",
    "label = torch.randint(0, 2, (2,))\n",
    "out = m(a, labels = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48bf4fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6387, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e8c1aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifierOutput(loss=tensor(0.6387, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.0029,  0.0407],\n",
       "        [-0.1544,  0.0349]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c9c86c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03452424",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_PATH = '/datascope/subaru/user/swei20/model/bosz50000_mask.npy'\n",
    "import numpy as np\n",
    "\n",
    "#region --DATA-----------------------------------------------------------\n",
    "class SpecTrainDataset(BaseSpecDataset):\n",
    "    def load_data(self, stage=None) -> None:\n",
    "        super().load_data(stage=stage)\n",
    "        if self.mask_ratio is not None:\n",
    "            if self.mask_ratio < 1:\n",
    "                self.mask = np.load(MASK_PATH)\n",
    "                self.apply_mask()\n",
    "    \n",
    "class SpecTestDataset(BaseSpecDataset):\n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset, stage='test'):\n",
    "        keys = ['file_path', 'val_path', 'test_path', 'num_samples', 'num_test_samples', 'root_dir', 'mask_ratio', 'mask_filler', 'mask', 'lvrg_num', 'lvrg_mask', 'noise_level', 'noise_max']\n",
    "        c = cls(**{k: getattr(dataset, k) for k in keys}) \n",
    "        if stage == 'val': c.num_test_samples = min(c.num_test_samples, 1000) \n",
    "        return c\n",
    "    def load_data(self, stage=None) -> None:\n",
    "        super().load_data(stage=stage)\n",
    "        if self.mask is None and self.mask_ratio is not None:\n",
    "            if self.mask_ratio < 1:\n",
    "                self.mask = np.load(MASK_PATH)\n",
    "            # self.mask = self.create_quantile_mask(self.error, ratio=self.mask_ratio)\n",
    "        if self.mask is not None: \n",
    "            self.mask_plot = {'wave': self.wave, 'error':self.error[0], 'mask': self.mask}\n",
    "            self.apply_mask()\n",
    "            self.mask_plot.update({'masked_error': self.error[0]})       \n",
    "        self.set_noise()    \n",
    "        \n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        return self.noisy[idx], self.flux[idx], self.error[idx]\n",
    "    \n",
    "    def set_noise(self, seed=42):\n",
    "        torch.manual_seed(seed)\n",
    "        self.noise = torch.randn_like(self.flux) * self.error * self.noise_level\n",
    "        self.noisy = self.flux + self.noise\n",
    "        self.flux_rms = torch.norm(self.flux, dim=-1)\n",
    "        self.snr0 = torch.div(self.flux_rms , torch.norm(self.noise, dim=-1))\n",
    "        \n",
    "    # def get_single_spectrum_noise_testset(self, sample_idx=0, repeat=1000, seed=42):\n",
    "    #     flux_0, error_0  = self.flux[sample_idx], self.error[sample_idx]\n",
    "    #     test_dataset = SingleSpectrumNoiseDataset(flux_0, error_0, noise_level=self.noise_level,repeat=repeat, seed=seed)\n",
    "    #     return test_dataset\n",
    "    \n",
    "#endregion --DATA-----------------------------------------------------------\n",
    "#region --DATAMODULE-----------------------------------------------------------\n",
    "class SpecDataModule(BaseDataModule):\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return super().from_config(dataset_cls=SpecTrainDataset, config=config)\n",
    "    def setup_test_dataset(self, stage):\n",
    "        if hasattr(self, 'train'):\n",
    "            return SpecTestDataset.from_dataset(self.train, stage) \n",
    "        return SpecTestDataset.from_config(self.config)\n",
    "#endregion --DATAMODULE-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d26b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassSpecDataset(BaseSpecDataset):\n",
    "    def __init__(self, param_idx=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.param_idx = param_idx  # 指定使用哪个参数作为标签\n",
    "        \n",
    "    def load_data(self, stage=None):\n",
    "        super().load_data(stage)\n",
    "        self.load_params(stage)\n",
    "        self.labels = (torch.tensor(self.logg > 2.5)).long() \n",
    "        \n",
    "        # 将连续参数离散化为分类标签\n",
    "        # params = torch.tensor(getattr(self, ['teff', 'logg', 'mh'][self.param_idx]))\n",
    "        # self.labels = self.discretize_params(params)\n",
    "        \n",
    "    def discretize_params(self, params, bins=10):\n",
    "        # 等频分箱创建分类标签\n",
    "        quantiles = torch.linspace(0, 1, bins+1)\n",
    "        bin_edges = torch.quantile(params, quantiles)\n",
    "        return torch.bucketize(params, bin_edges[1:-1]).long()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        flux, error = super().__getitem__(idx)\n",
    "        return flux, error, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4430ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datascope/subaru/user/swei20/data/bosz50000/test/mag215/train_100k/dataset.h5 1000 /datascope/subaru/user/swei20/data/bosz50000/mag215/val_1k/dataset.h5 1000 /datascope/subaru/user/swei20/data/bosz50000/mag215/train_1k/dataset.h5 None ./results\n"
     ]
    }
   ],
   "source": [
    "c = ClassSpecDataset.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8aa929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from /datascope/subaru/user/swei20/data/bosz50000/test/mag215/train_100k/dataset.h5 1000\n",
      "torch.Size([1000, 4096]) torch.Size([1000, 4096]) torch.Size([4096]) 1000 4096\n"
     ]
    }
   ],
   "source": [
    "c.load_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba0d1660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5135, 0.6785, 0.5748,  ..., 0.4817, 0.4453, 0.4898]),\n",
       " tensor([0.0587, 0.0587, 0.0572,  ..., 0.0632, 0.0564, 0.0564]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96e9351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTDataModule(BaseDataModule):\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return super().from_config(dataset_cls=ClassSpecDataset, config=config)\n",
    "    def setup_test_dataset(self, stage):\n",
    "        return ClassSpecDataset.from_config(self.config)\n",
    "    # def setup(self, stage=None):\n",
    "    #     super().setup(stage)\n",
    "    #     # 添加通道维度 (B, L) -> (B, 1, L)\n",
    "    #     self.train.flux = self.train.flux.unsqueeze(1)\n",
    "    #     self.train.error = self.train.error.unsqueeze(1)\n",
    "    #     self.val.flux = self.val.flux.unsqueeze(1)\n",
    "    #     self.val.error = self.val.error.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ec4d17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datascope/subaru/user/swei20/data/bosz50000/test/mag215/train_100k/dataset.h5 1000 /datascope/subaru/user/swei20/data/bosz50000/mag215/val_1k/dataset.h5 1000 /datascope/subaru/user/swei20/data/bosz50000/mag215/train_1k/dataset.h5 None ./results\n",
      "loading data from /datascope/subaru/user/swei20/data/bosz50000/test/mag215/train_100k/dataset.h5 1000\n",
      "torch.Size([1000, 4096]) torch.Size([1000, 4096]) torch.Size([4096]) 1000 4096\n",
      "/datascope/subaru/user/swei20/data/bosz50000/test/mag215/train_100k/dataset.h5 1000 /datascope/subaru/user/swei20/data/bosz50000/mag215/val_1k/dataset.h5 1000 /datascope/subaru/user/swei20/data/bosz50000/mag215/train_1k/dataset.h5 None ./results\n",
      "loading data from /datascope/subaru/user/swei20/data/bosz50000/mag215/train_1k/dataset.h5 1000\n",
      "torch.Size([1000, 4096]) torch.Size([1000, 4096]) torch.Size([4096]) 1000 4096\n"
     ]
    }
   ],
   "source": [
    "dd = ViTDataModule.from_config(config)\n",
    "dd.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f49c572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ClassSpecDataset at 0x7f945ad64190>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c50444c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.3198, 0.2749, 0.3066,  ..., 0.5203, 0.5208, 0.5208],\n",
      "        [0.5668, 0.5674, 0.5675,  ..., 0.4417, 0.4414, 0.4416],\n",
      "        [0.6054, 0.6077, 0.6191,  ..., 0.4398, 0.4393, 0.4391],\n",
      "        ...,\n",
      "        [0.5923, 0.5635, 0.5696,  ..., 0.4658, 0.4704, 0.4721],\n",
      "        [0.6074, 0.6073, 0.6073,  ..., 0.4152, 0.4156, 0.4155],\n",
      "        [0.1181, 0.1411, 0.1168,  ..., 0.7641, 0.8004, 0.7934]]), tensor([[0.1139, 0.1139, 0.1131,  ..., 0.1299, 0.1167, 0.1167],\n",
      "        [0.1397, 0.1397, 0.1384,  ..., 0.1555, 0.1389, 0.1389],\n",
      "        [0.0603, 0.0603, 0.0599,  ..., 0.0679, 0.0598, 0.0598],\n",
      "        ...,\n",
      "        [0.0399, 0.0399, 0.0397,  ..., 0.0443, 0.0395, 0.0395],\n",
      "        [0.1311, 0.1311, 0.1298,  ..., 0.1475, 0.1309, 0.1309],\n",
      "        [0.0731, 0.0731, 0.0721,  ..., 0.0891, 0.0801, 0.0801]]), tensor([1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6826)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "d = DataLoader(c, batch_size=100, num_workers=0, shuffle=True)\n",
    "with torch.no_grad():\n",
    "    for batch in d:\n",
    "        print(batch)\n",
    "        flux, error, labels = batch\n",
    "        flux = flux.to(m.device)\n",
    "        error = error.to(m.device)\n",
    "        labels = labels.to(m.device)\n",
    "\n",
    "        output = m(flux, labels=labels)\n",
    "        \n",
    "        break\n",
    "output.loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a087d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc =Accuracy(task='multiclass', num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "462c9f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5600)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc(output.logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fff5ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.basemodule import BaseTrainer\n",
    "t = BaseTrainer(config, num_gpus=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420497d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.basemodule import BaseLightningModule\n",
    "lm = BaseLightningModule.from_config(config, model_cls=MyViT, dataset_cls=ClassSpecDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6e623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ac0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "class ViTLModule(BaseLightningModule):\n",
    "    def __init__(self, model, data_module, config):\n",
    "        super().__init__(model=model, data_module=data_module, config=config)\n",
    "        self.save_hyperparameters()\n",
    "        self.loss_name = 'train'  # Set the loss name for logging\n",
    "        self.model.loss_name = self.loss_name  # Ensure the model has the loss name set\n",
    "        self.get_accuracy = Accuracy(task='multiclass', num_classes=config['num_labels'])\n",
    "\n",
    "    def forward(self, flux, labels, loss_only=True):\n",
    "        outputs = self.model(flux, labels=labels)\n",
    "        if loss_only:\n",
    "            return outputs.loss\n",
    "        else:\n",
    "            return outputs\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        flux, _, labels = batch\n",
    "        loss = self.forward(flux, labels, loss_only=True)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        flux, _, labels = batch\n",
    "        outputs = self.forward(flux, labels, loss_only=False)\n",
    "        self.log('val_loss', outputs.loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        accuracy = self.get_accuracy(outputs.logits, labels)\n",
    "        self.log('val_acc', accuracy, on_step=False, on_epoch=True,  prog_bar=False)\n",
    "        return outputs.loss\n",
    "        \n",
    "lm = ViTLModule(model=m, data_module=dd, config=config)\n",
    "t.fit(lm,datamodule=lm.data_module) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58ab58e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.loss_name = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab0b98b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/local/tmp/swei20/miniconda3/envs/viska-torch-3/lib/python3.13/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /srv/local/tmp/swei20/miniconda3/envs/viska-torch-3/ ...\n",
      "/srv/local/tmp/swei20/miniconda3/envs/viska-torch-3/lib/python3.13/site-packages/lightning/pytorch/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datascope/subaru/user/swei20/data/bosz50000/test/mag215/train_100k/dataset.h5 1000 /datascope/subaru/user/swei20/data/bosz50000/mag215/val_1k/dataset.h5 1000 /datascope/subaru/user/swei20/data/bosz50000/mag215/train_1k/dataset.h5 None ./results\n",
      "loading data from /datascope/subaru/user/swei20/data/bosz50000/test/mag215/train_100k/dataset.h5 1000\n",
      "torch.Size([1000, 4096]) torch.Size([1000, 4096]) torch.Size([4096]) 1000 4096\n",
      "/datascope/subaru/user/swei20/data/bosz50000/test/mag215/train_100k/dataset.h5 1000 /datascope/subaru/user/swei20/data/bosz50000/mag215/val_1k/dataset.h5 1000 /datascope/subaru/user/swei20/data/bosz50000/mag215/train_1k/dataset.h5 None ./results\n",
      "loading data from /datascope/subaru/user/swei20/data/bosz50000/mag215/train_1k/dataset.h5 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/local/tmp/swei20/miniconda3/envs/viska-torch-3/lib/python3.13/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/swei20/VIT/evals/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]\n",
      "\n",
      "  | Name  | Type  | Params | Mode \n",
      "----------------------------------------\n",
      "0 | model | MyViT | 1.2 M  | train\n",
      "----------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.834     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 4096]) torch.Size([1000, 4096]) torch.Size([4096]) 1000 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "lm = ViTLModule(model=m, data_module=dd, config=config)\n",
    "t.fit(lm,datamodule=lm.data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ec92295",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data': {'file_path': '/home/swei20/SirenSpec/tests/spec/test_dataset.h5', 'num_samples': 10},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15ee2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31f9f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, config, use_wandb=False, num_gpus=None, sweep=False, ckpt_path=None):\n",
    "        # 创建数据模块\n",
    "        dm = ViTDataModule.from_config(config)\n",
    "        dm.setup()\n",
    "        \n",
    "        # 创建模型\n",
    "        model = ViTModel(config, num_labels=config.get('num_classes', 10))\n",
    "        \n",
    "        # 创建Lightning模块\n",
    "        self.lightning_module = ViTLightningModule(model, dm, config)\n",
    "        \n",
    "        # 其余初始化保持不变...\n",
    "        self.lightning_module.sweep = sweep\n",
    "        if use_wandb:\n",
    "            logger = L.pytorch.loggers.WandbLogger(\n",
    "                project=config['project'],\n",
    "                config=config,\n",
    "                name=config.get('exp_name', 'ViT_experiment'),\n",
    "                log_model=True\n",
    "            )\n",
    "        else:\n",
    "            logger = None\n",
    "            \n",
    "        self.t = SpecTrainer(config=config, logger=logger, \n",
    "                            num_gpus=num_gpus, sweep=sweep)\n",
    "        self.ckpt_path = ckpt_path\n",
    "\n",
    "    # run方法保持不变..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f5129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viska-torch-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
